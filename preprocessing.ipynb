{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Setup and Libraries Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python-headless mtcnn tensorflow keras scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from mtcnn import MTCNN\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Load Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_path = 'train_sample_videos/metadata.json'\n",
    "\n",
    "with open(metadata_path, 'r') as file:\n",
    "    metadata = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Extract Frames from Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_frames(video_path, output_folder, frame_rate=1):\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    count = 0\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        if int(cap.get(cv2.CAP_PROP_POS_FRAMES)) % frame_rate == 0:\n",
    "            cv2.imwrite(os.path.join(output_folder, f\"frame{count:05d}.jpg\"), frame)\n",
    "            count += 1\n",
    "    cap.release()\n",
    "\n",
    "train_videos_path = 'train_sample_videos'\n",
    "test_videos_path = 'test_videos'\n",
    "output_frames_path = 'extracted_frames'\n",
    "\n",
    "# Process train videos\n",
    "for video_file in os.listdir(train_videos_path):\n",
    "    if video_file.endswith('.mp4'):\n",
    "        video_path = os.path.join(train_videos_path, video_file)\n",
    "        extract_frames(video_path, os.path.join(output_frames_path, 'train', video_file.split('.')[0]))\n",
    "\n",
    "# Process test videos\n",
    "for video_file in os.listdir(test_videos_path):\n",
    "    if video_file.endswith('.mp4'):\n",
    "        video_path = os.path.join(test_videos_path, video_file)\n",
    "        extract_frames(video_path, os.path.join(output_frames_path, 'test', video_file.split('.')[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Face Detection and Cropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_and_crop_faces(image_path, output_folder, frame_number):\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    detector = MTCNN()\n",
    "    img = cv2.imread(image_path)\n",
    "    faces = detector.detect_faces(img)\n",
    "    if not faces:\n",
    "        print(f\"No faces detected in {image_path}\")\n",
    "    count = 0\n",
    "    for face in faces:\n",
    "        x, y, width, height = face['box']\n",
    "        cropped_face = img[y:y+height, x:x+width]\n",
    "        cv2.imwrite(os.path.join(output_folder, f\"frame{frame_number:05d}_face{count:05d}.jpg\"), cropped_face)\n",
    "        count += 1\n",
    "\n",
    "output_faces_path = 'cropped_faces'\n",
    "\n",
    "# Process train frames\n",
    "for video_folder in os.listdir(os.path.join(output_frames_path, 'train')):\n",
    "    frame_folder_path = os.path.join(output_frames_path, 'train', video_folder)\n",
    "    face_output_folder = os.path.join(output_faces_path, 'train', video_folder)\n",
    "    for frame_number, frame_file in enumerate(os.listdir(frame_folder_path)):\n",
    "        frame_path = os.path.join(frame_folder_path, frame_file)\n",
    "        detect_and_crop_faces(frame_path, face_output_folder, frame_number)\n",
    "\n",
    "# Process test frames\n",
    "for video_folder in os.listdir(os.path.join(output_frames_path, 'test')):\n",
    "    frame_folder_path = os.path.join(output_frames_path, 'test', video_folder)\n",
    "    face_output_folder = os.path.join(output_faces_path, 'test', video_folder)\n",
    "    for frame_number, frame_file in enumerate(os.listdir(frame_folder_path)):\n",
    "        frame_path = os.path.join(frame_folder_path, frame_file)\n",
    "        detect_and_crop_faces(frame_path, face_output_folder, frame_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "def augment_images(image_folder, output_folder, num_augmented_images=5):\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    for img in os.listdir(image_folder):\n",
    "        img_path = os.path.join(image_folder, img)\n",
    "        image = cv2.imread(img_path)\n",
    "        x = image.reshape((1,) + image.shape)\n",
    "        i = 0\n",
    "        for batch in datagen.flow(x, batch_size=1, save_to_dir=output_folder, save_prefix='aug', save_format='jpg'):\n",
    "            i += 1\n",
    "            if i >= num_augmented_images:\n",
    "                break\n",
    "\n",
    "output_augmented_path = 'augmented_faces'\n",
    "\n",
    "# Augment train faces\n",
    "for video_folder in os.listdir(os.path.join(output_faces_path, 'train')):\n",
    "    face_folder_path = os.path.join(output_faces_path, 'train', video_folder)\n",
    "    augmented_output_folder = os.path.join(output_augmented_path, 'train', video_folder)\n",
    "    augment_images(face_folder_path, augmented_output_folder)\n",
    "\n",
    "# Augment test faces\n",
    "for video_folder in os.listdir(os.path.join(output_faces_path, 'test')):\n",
    "    face_folder_path = os.path.join(output_faces_path, 'test', video_folder)\n",
    "    augmented_output_folder = os.path.join(output_augmented_path, 'test', video_folder)\n",
    "    augment_images(face_folder_path, augmented_output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Normalization and Resizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path, target_size=(224, 224)):\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.resize(img, target_size)\n",
    "    img = img.astype('float32') / 255.0  # Normalize to 0-1\n",
    "    return img\n",
    "\n",
    "# Preprocess train images\n",
    "preprocessed_train_images = []\n",
    "train_labels = []\n",
    "for video_folder in os.listdir(os.path.join(output_augmented_path, 'train')):\n",
    "    augmented_folder_path = os.path.join(output_augmented_path, 'train', video_folder)\n",
    "    label = 1 if metadata[video_folder + '.mp4']['label'] == 'FAKE' else 0\n",
    "    for img_file in os.listdir(augmented_folder_path):\n",
    "        img_path = os.path.join(augmented_folder_path, img_file)\n",
    "        preprocessed_train_images.append(preprocess_image(img_path))\n",
    "        train_labels.append(label)\n",
    "\n",
    "# Preprocess test images\n",
    "preprocessed_test_images = []\n",
    "for video_folder in os.listdir(os.path.join(output_augmented_path, 'test')):\n",
    "    augmented_folder_path = os.path.join(output_augmented_path, 'test', video_folder)\n",
    "    for img_file in os.listdir(augmented_folder_path):\n",
    "        img_path = os.path.join(augmented_folder_path, img_file)\n",
    "        preprocessed_test_images.append(preprocess_image(img_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Create Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, val_images, train_labels, val_labels = train_test_split(preprocessed_train_images, train_labels, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Batch Processing and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator()\n",
    "val_datagen = ImageDataGenerator()\n",
    "test_datagen = ImageDataGenerator()\n",
    "\n",
    "train_generator = train_datagen.flow(np.array(train_images), np.array(train_labels), batch_size=32)\n",
    "val_generator = val_datagen.flow(np.array(val_images), np.array(val_labels), batch_size=32)\n",
    "test_generator = test_datagen.flow(np.array(preprocessed_test_images), batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of visualizing a preprocessed image\n",
    "plt.imshow(preprocessed_train_images[0])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
