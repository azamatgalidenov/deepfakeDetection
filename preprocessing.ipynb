{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Setup and Libraries Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python-headless mtcnn tensorflow keras scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-29 20:58:13.527557: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-06-29 20:58:13.554727: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-29 20:58:13.960491: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from mtcnn import MTCNN\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Load Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_path = 'data/train_sample_videos/metadata.json'\n",
    "\n",
    "with open(metadata_path, 'r') as file:\n",
    "    metadata = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Extract Frames from Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_frames(video_path, output_folder, frame_rate=1):\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    count = 0\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        if int(cap.get(cv2.CAP_PROP_POS_FRAMES)) % frame_rate == 0:\n",
    "            cv2.imwrite(os.path.join(output_folder, f\"frame{count:05d}.jpg\"), frame)\n",
    "            count += 1\n",
    "    cap.release()\n",
    "\n",
    "train_videos_path = 'data/train_sample_videos'\n",
    "test_videos_path = 'data/test_videos'\n",
    "output_frames_path = 'data/extracted_frames'\n",
    "\n",
    "# Process train videos\n",
    "for video_file in os.listdir(train_videos_path):\n",
    "    if video_file.endswith('.mp4'):\n",
    "        video_path = os.path.join(train_videos_path, video_file)\n",
    "        extract_frames(video_path, os.path.join(output_frames_path, 'train', video_file.split('.')[0]))\n",
    "\n",
    "# Process test videos\n",
    "for video_file in os.listdir(test_videos_path):\n",
    "    if video_file.endswith('.mp4'):\n",
    "        video_path = os.path.join(test_videos_path, video_file)\n",
    "        extract_frames(video_path, os.path.join(output_frames_path, 'test', video_file.split('.')[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Face Detection and Cropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 26\u001b[0m\n\u001b[1;32m     23\u001b[0m output_frames_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/extracted_frames\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Process train frames\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m video_folder \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241m.\u001b[39mlistdir(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_frames_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m)):\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m train_fake_count \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m metadata[video_folder \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.mp4\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFAKE\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     28\u001b[0m         frame_folder_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_frames_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m, video_folder)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "def detect_and_crop_faces(image_path, output_folder, frame_number):\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    detector = MTCNN()\n",
    "    img = cv2.imread(image_path)\n",
    "    faces = detector.detect_faces(img)\n",
    "    if not faces:\n",
    "        print(f\"No faces detected in {image_path}\")\n",
    "    count = 0\n",
    "    for face in faces:\n",
    "        x, y, width, height = face['box']\n",
    "        cropped_face = img[y:y+height, x:x+width]\n",
    "        cv2.imwrite(os.path.join(output_folder, f\"frame{frame_number:05d}_face{count:05d}.jpg\"), cropped_face)\n",
    "        count += 1\n",
    "\n",
    "output_faces_path = 'data/cropped_faces'\n",
    "train_fake_count = 0\n",
    "train_real_count = 0\n",
    "test_count = 0\n",
    "\n",
    "train_videos_path = 'data/train_sample_videos'\n",
    "test_videos_path = 'data/test_videos'\n",
    "output_frames_path = 'data/extracted_frames'\n",
    "\n",
    "# Process train frames\n",
    "for video_folder in os.listdir(os.path.join(output_frames_path, 'train')):\n",
    "    if train_fake_count < 3 and metadata[video_folder + '.mp4']['label'] == 'FAKE':\n",
    "        frame_folder_path = os.path.join(output_frames_path, 'train', video_folder)\n",
    "        face_output_folder = os.path.join(output_faces_path, 'train', video_folder)\n",
    "        train_fake_count += 1\n",
    "\n",
    "        for frame_number, frame_file in enumerate(os.listdir(frame_folder_path)):\n",
    "            frame_path = os.path.join(frame_folder_path, frame_file)\n",
    "            detect_and_crop_faces(frame_path, face_output_folder, frame_number)\n",
    "\n",
    "    elif train_real_count < 3 and metadata[video_folder + '.mp4']['label'] == 'REAL':\n",
    "        frame_folder_path = os.path.join(output_frames_path, 'train', video_folder)\n",
    "        face_output_folder = os.path.join(output_faces_path, 'train', video_folder)\n",
    "        train_real_count += 1\n",
    "\n",
    "        for frame_number, frame_file in enumerate(os.listdir(frame_folder_path)):\n",
    "            frame_path = os.path.join(frame_folder_path, frame_file)\n",
    "            detect_and_crop_faces(frame_path, face_output_folder, frame_number)\n",
    "\n",
    "\"\"\"\n",
    "#get test videos from train set\n",
    "# Process test frames\n",
    "for video_folder in os.listdir(os.path.join(output_frames_path, 'train')):\n",
    "    if test_count < 5 and (video_folder not in os.listdir(\"data/cropped_faces/train\")):\n",
    "        frame_folder_path = os.path.join(output_frames_path, 'train', video_folder)\n",
    "        face_output_folder = os.path.join(output_faces_path, 'test', video_folder)\n",
    "        test_count += 1\n",
    "\n",
    "        for frame_number, frame_file in enumerate(os.listdir(frame_folder_path)):\n",
    "            frame_path = os.path.join(frame_folder_path, frame_file)\n",
    "            detect_and_crop_faces(frame_path, face_output_folder, frame_number)\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "# Process test frames\n",
    "for video_folder in os.listdir(os.path.join(output_frames_path, 'test')):\n",
    "    if test_count < 5:\n",
    "        frame_folder_path = os.path.join(output_frames_path, 'test', video_folder)\n",
    "        face_output_folder = os.path.join(output_faces_path, 'test', video_folder)\n",
    "        test_count += 1\n",
    "        \n",
    "        for frame_number, frame_file in enumerate(os.listdir(frame_folder_path)):\n",
    "            frame_path = os.path.join(frame_folder_path, frame_file)\n",
    "            detect_and_crop_faces(frame_path, face_output_folder, frame_number)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# Augment test faces\\nfor video_folder in os.listdir(os.path.join(output_faces_path, 'test')):\\n    face_folder_path = os.path.join(output_faces_path, 'test', video_folder)\\n    augmented_output_folder = os.path.join(output_augmented_path, 'test', video_folder)\\n    augment_images(face_folder_path, augmented_output_folder)\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "def augment_images(image_folder, output_folder, num_augmented_images=5):\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    for img in os.listdir(image_folder):\n",
    "        img_path = os.path.join(image_folder, img)\n",
    "        image = cv2.imread(img_path)\n",
    "        x = image.reshape((1,) + image.shape)\n",
    "        i = 0\n",
    "        for batch in datagen.flow(x, batch_size=1, save_to_dir=output_folder, save_prefix='aug', save_format='jpg'):\n",
    "            i += 1\n",
    "            if i >= num_augmented_images:\n",
    "                break\n",
    "\n",
    "output_augmented_path = 'data/augmented_faces'\n",
    "output_faces_path = 'data/cropped_faces'\n",
    "\n",
    "\n",
    "# Augment train faces\n",
    "for video_folder in os.listdir(os.path.join(output_faces_path, 'train')):\n",
    "    face_folder_path = os.path.join(output_faces_path, 'train', video_folder)\n",
    "    augmented_output_folder = os.path.join(output_augmented_path, 'train', video_folder)\n",
    "    augment_images(face_folder_path, augmented_output_folder)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "# Augment test faces\n",
    "for video_folder in os.listdir(os.path.join(output_faces_path, 'test')):\n",
    "    face_folder_path = os.path.join(output_faces_path, 'test', video_folder)\n",
    "    augmented_output_folder = os.path.join(output_augmented_path, 'test', video_folder)\n",
    "    augment_images(face_folder_path, augmented_output_folder)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Normalization and Resizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path, target_size=(224, 224)):\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.resize(img, target_size)\n",
    "    img = img.astype('float32') / 255.0  # Normalize to 0-1\n",
    "    return img\n",
    "\n",
    "# Preprocess train images\n",
    "preprocessed_train_images = []\n",
    "train_labels = []\n",
    "for video_folder in os.listdir(os.path.join(output_augmented_path, 'train')):\n",
    "    augmented_folder_path = os.path.join(output_augmented_path, 'train', video_folder)\n",
    "    label = 1 if metadata[video_folder + '.mp4']['label'] == 'FAKE' else 0\n",
    "    for img_file in os.listdir(augmented_folder_path):\n",
    "        img_path = os.path.join(augmented_folder_path, img_file)\n",
    "        preprocessed_train_images.append(preprocess_image(img_path))\n",
    "        train_labels.append(label)\n",
    "\n",
    "# Preprocess test images\n",
    "preprocessed_test_images = []\n",
    "for video_folder in os.listdir(os.path.join(output_augmented_path, 'test')):\n",
    "    augmented_folder_path = os.path.join(output_augmented_path, 'test', video_folder)\n",
    "    for img_file in os.listdir(augmented_folder_path):\n",
    "        img_path = os.path.join(augmented_folder_path, img_file)\n",
    "        preprocessed_test_images.append(preprocess_image(img_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Create Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, val_images, train_labels, val_labels = train_test_split(preprocessed_train_images, train_labels, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Batch Processing and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator()\n",
    "val_datagen = ImageDataGenerator()\n",
    "test_datagen = ImageDataGenerator()\n",
    "\n",
    "train_generator = train_datagen.flow(np.array(train_images), np.array(train_labels), batch_size=32)\n",
    "val_generator = val_datagen.flow(np.array(val_images), np.array(val_labels), batch_size=32)\n",
    "test_generator = test_datagen.flow(np.array(preprocessed_test_images), batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of visualizing a preprocessed image\n",
    "plt.imshow(preprocessed_train_images[0])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
